## (П]|(РС)|(РП) Оценочная функция

Допустим, отслеживаются перемещения человека, гуляющего вдоль камеры. В каждом кадре происходит фиксация местоположения этого человека. Это может быть сделано любым, описанным ранее, способом, но в каждом отдельном случае ищется оценка положения человека в каждом кадре. Скорее всего, эта оценка будет не совсем точной. Причин для этого множество. Это может быть связано и с не точностью датчика, и от использования приближений на ранних этапах обработки, и с вопросами, связанные с сокрытиями или тенями, или с возможной сменой формы из-за того, что человек во время перемещений размахивает руками и ногами. Независимо от источника, ожидается, что изменения будут меняться несколько беспорядочно, а о "фактических" значениях может идти речь лишь при наличии идеализированного датчика. Можно представить все эти неточности как простое добавление шума к процессу отслеживания.

Необходимо иметь возможность оценки передвижений этого человека за счет максимально возможного использования сделанных измерений. Таким образом, совокупный эффект от всех измерений позволяет обнаруживать часть перемещений человека, не зависящих от шума. Ключевым дополнительным ингредиентом является *модель* перемещений человека. Например, можно смоделировать перемещение человека со следующим утверждением: "Человек попадает в кадр с одной стороны и перемещается вдоль кадра с постоянной скоростью". За счет такой модели можно определить не только местоположение человека, но и какие параметры модели поддерживают данное наблюдение.

Данная задача разбивается на два этапа (рисунок 10-18). Первый этап, как правило, именуется этапом предсказаний, в котором используется информация, полученная в прошлом, для улучшения модели с местоположением человека (или предмета). Второй этап, этап коррекции, производит измерение с последующим сопоставлением с предсказанными ранее измерениями.

![Рисунок 10-18 не найден](Images/Pic_10_18.jpg)

Рисунок 10-18. Двухэтапный цикл оценки: предсказание на основе предыдущих данных с последующим применением новых измерений

Принцип действия задачи двухэтапной оценки соответствует оценке наиболее популярного метода, использующего *фильтр Kalman*. В дополнение к этому методу, есть ещё один наиболее важный метод, *алгоритм condensation*, реализующий широкий класс методов, известных как фильтры частиц. Основное различие между фильтром Kalman и алгоритмом condensation сводится к описанию плотности вероятного состояния. Данное различие будет более подробно рассмотрено в следующих разделах.

### Фильтр Kalman

!!! Нумерацию формул подправить !!!

С момента первых упоминаний (1960 г.) о фильтре Kalman его значение заметно возросло. Основная идея фильтра Kalman заключается в том, что при строгом, но разумно, наборе предположений можно – при учете истории изменений системы - построить модель состояний системы, которая максимизирует *posterior* вероятность предыдущих изменений. Более подробную информацию можно найти в работах Welsh и Bishop. Кроме того, можно максимизировать *posterior* (это академический жаргон, означающий "взгляд в прошлое"; таким образом, когда говорят, что такое то распределение "максимизирует posteriori вероятность", то это можно трактовать как "что на самом деле произошло") вероятность без ведения длинной истории предыдущих изменений. Вместо этого происходит многократное обновление модели состояний системы и сохранение этой модели для последующей итерации. Это значительно упрощает вычислительную часть этого метода. 

Перед тем, как переходить к деталям, необходимо уделить немного времени на обсуждение предположений. Имеется три важных предположения, необходимые для теоретического истолкования фильтра Kalman: (1) моделируемая система линейна, (2) шум – это измерения, сделанные вне "белого", и (3) этот шум имеет Gaussian природу. Первое предположение означает, что состояние системы в момент времени *k* может быть смоделирована как некая матрица, помноженная на состояние в момент времени *k - 1*. Остальные предположения означают, что шум не коррелируется во времени, а его амплитуда может быть точно смоделирована только при помощи среднего значения и ковариации (т.е. шум полностью можно описать при помощи первых и вторых моментов). Эти предположения могут показаться ограниченными, однако, на самом деле они охватывают множество случаев (единственное, что стоит учесть, так это то, что если начальное состояние (например) имеет шансы 50×50, то потребуется использовать что-то более сложное, чем только фильтр Kalman).

Что же означает "максимизация posteriori вероятности предыдущих изменений"? Это означает, что новая модель строиться после проведения измерений – с учетом неопределенности предыдущей модели и нового значения - модели, обладающей лучшей вероятностью быть правильной. Это означает, что фильтр Kalman, с учетом трех предположений, является лучшим способом объединения данных из различных источников или из одного, но с данными полученными в разные моменты времени. 

При наличии уже знакомой информации происходит получение новой информации, с последующим изменением уже знакомой информации, основываясь на надежности старой и новой информации в соответствии с взвешенным сочетанием старого и нового. 

Далее будет более подробно рассмотрен принцип работы фильтра на примере одномерного движения. Его можно пропустить и перейти к следующему разделу.

**Немного математики Kalman**

Так в чем же суть фильтра Kalman? - *сплав информации*. Например, необходимо узнать, где некая точка находиться на линии (одномерный сценарий). В результате наличия шума имеется два ненадежных (в Гауссовом смысле) места: ![Рисунок 10- не найден](Images/Frml_10_.jpg) и ![Рисунок 10- не найден](Images/Frml_10_.jpg). Гауссова неопределенность имеет значения ![Рисунок 10- не найден](Images/Frml_10_.jpg) и ![Рисунок 10- не найден](Images/Frml_10_.jpg) в совокупности со стандартными отклонениями ![Рисунок 10- не найден](Images/Frml_10_.jpg) и ![Рисунок 10- не найден](Images/Frml_10_.jpg). Стандартные отклонения – это выражение неопределенности относительно того, насколько хороши измерения. Распределение вероятности в зависимости от локаций именуется *Гауссовым распределением*:

![Рисунок 10- не найден](Images/Frml_10_.jpg)

При наличии двух таких измерений, каждое с Гауссовым распределением вероятности, можно ожидать, что плотность вероятности при некотором значении *x* и учете обоих измерений будет пропорциональна ![Рисунок 10- не найден](Images/Frml_10_.jpg). Оказывается, этот результат является ещё одним распределением гаусса, для которого можно вычислить среднее значение и стандартное отклонение следующим образом: при условии, что 

![Рисунок 10- не найден](Images/Frml_10_.jpg)

а также при условии, что распределение гаусса имеет максимум в среднем значение, можно найти это среднее значение просто вычислив производную *p(x)* по *x*. Производная функции в точке максимума равна 0:

![Рисунок 10- не найден](Images/Frml_10_.jpg)

Т.к функция распределения вероятности *p(x)* никогда не равна 0, то выражение в скобках должно быть равно 0. Решение данного уравнения для *x* дает очень важное соотношение:

![Рисунок 10- не найден](Images/Frml_10_.jpg)

Это новое среднее значение ![Рисунок 10- не найден](Images/Frml_10_.jpg) является просто взвешенной суммой двух измерений средних, где взвешивание определяется относительно неопределенности двух измерений. При этом, например, если неопределенность ![Рисунок 10- не найден](Images/Frml_10_.jpg) второго измерения особенно велика, то новое среднее по существу будет таким же, как среднее ![Рисунок 10- не найден](Images/Frml_10_.jpg) для ранее определенного измерения.