## (П]|(РС)|(РП) Стерео зрение

Теперь все готово для рассмотрения *стерео зрения*. (В данном разделе будет рассмотрена только "верхушка айсберга". Для получения более подробной информации лучше всего обратиться к статьям: Trucco и Verri, Hartley и Zisserman, Forsyth и Ponce, и Shapiro и Stockman.) Всем нам знакомы возможности стерео зрения, которые дают нам наши глаза. Возникает вопрос: до какой степени возможно подражать этой возможности в вычислительных системах? Компьютеры выполняют данную задачу за счет нахождения соответствия между точками, которые видны на одном фотоприёмнике и теме же точками на другом фотоприёмнике. За счет этого соответствия и заранее известного базового разделения между камерами, возможно вычислить трехмерное расположенеи точек. Хотя поиск соотвествующих точек вычислительно дорогая опреация, можно воспользоваться знаниями о геометрии системы для наиболее возможного сужения пространства поиска. На практике, стерео зрение реализуется в четыре этапа при помощи двух камер.

1. Математически удалить радиальные и тангенциальные искажения объектива (глава 11). На выходе будет получено неискаженное изображение.

2. НАстройка углов и расстояния между камерами, так называемый процесс *уточнения*. На выходе будут получены выровненные по строкам (это означает, что два изображения плоскости компланарны и что строки изображения будут выровнены точно, т.е. в одном направлении имеют одинаковую y-координату) и уточненные изображения.

3. Поиск особенностей на представлениях левой и правой камер (каждый раз при упоминании на левую и правую камеры также подразумевает вертикально ориентированные верхняя и нижняя камеры, где диспропорция возникает по y-координате, а не по x), так называемый процесс *соответствия*. На выходе будет получена *карта несоответствий*, где различия будут соответствовать различиям в x-координате плоскости изображения для одного и того же рассматриваемого признака левой и правой камер: ![Формула 12-5 не найдена](Images/Frml_12_5.jpg).

4. Зная геометрическое расположенеи камер, можно развернуть карту несоответствий за счет *триангуляции*. Это так называемое *перепроецирование*, в результате чего получается карта глубины.

Для начала будет рассмотрен последний шаг, являющийся причиной появления первых трех.

### Триангуляция

Пусть имеется совершенно неискаженная, выравненная и измеренная стерео установка, показанная на рисунке 12-4: две камеры, чьи плоскости изображения компланары с точно параллельными оптическими осями (оптическая ось - это луч, выходящий из центра проекции *O* и проходящий через основные точки *c*, более известный как *основной луч*), для которых известно расстояние между ними, и с одинаковыми фокальными расстояниями ![Формула 12-6 не найдена](Images/Frml_12_6.jpg). Кроме того, пусть *основные точки* ![Формула 12-7 не найдена](Images/Frml_12_7.jpg) уже откалиброваны, чтобы иметь теже координаты пикселей, что и соответствующие левому и правому изображениям. При этом ни в коем случае не нужно путать основные точки с центром изображения. Основной точкой является той, что соответствует пересечению главного луча и плоскости изображения. Это пересечение зависит от оси объектива. Как уже было показано в главе 11, плоскость изображения крайне редко выравнивается именно с объективом, поэтому почти всегда центр фотоприёмника не совпадает с основной точкой. 

![Рисунок 12-4 не найден](Images/Pic_12_4.jpg)

Рисунок 12-4. Совершенно неискаженная, выравненная стерео установка с извстными соответствиями, глубина Z може тбыть найдена при помощи подобия треугольнико; основные лучи начинаются от центра проекции ![Формула 12-8 не найдена](Images/Frml_12_8.jpg) и проходят через основные точки двух плоскостей изображения ![Формула 12-9 не найдена](Images/Frml_12_9.jpg)

Теперь пусть строки изображений выровнены, т.е. пиксель строки одной камеры выровнен в соответствии с пикселем строки другой камеры (). Такая камера именуется *фронтально параллельно расположенной*. Так же пусть имеется возможность найти точку P материального мира на левом и правом изображениях ![Формула 12-10 не найдена](Images/Frml_12_10.jpg), которые имеют соответствующие горизонтальные координаты ![Формула 12-5 не найдена](Images/Frml_12_5.jpg).

Для данного упрощенного случая ![Формула 12-5 не найдена](Images/Frml_12_5.jpg) - это горизонтальные позиции точек левого и правого фотоприёмника (соответственно), позволяющие показать, что глубина обратно пропорциональна различию между этими представлениями, где различие определяется довольно таки просто ![Формула 12-10 не найдена](Images/Frml_12_10.jpg). Данный случай показан на рисунке 12-4, благодаря которому можно с легкостью вывести глубину Z из подобия треугольников. Ссылаясь на рисунок, имеем:

![Формула 12-11 не найдена](Images/Frml_12_11.jpg)

(Эта формула основывается на основных лучах, пересекающихся в бесконечности. Однако, как будет показано в следующем разделе, стерео исправления получаются по отношению к основным точкам ![Формула 12-7 не найдена](Images/Frml_12_7.jpg). Для данной формулы основные лучи пересекаются в бесконечности, а основные точки имеют одинаковые координаты. Тем не менее, если основные лучи пересекаются на конечном расстоянии, то основные точки имеют разные координаты и потому уравнение глубины принимает следующий вид ![Формула 12-12 не найдена](Images/Frml_12_12.jpg).)

Так как глубина обратно пропорциональна d, то очевидна нелинейная связь между этими двумя элементами. Когда d близко к 0, то небольшие различия приводит к большим различиям глубины. Когда d велико, то небольшие различия не на много изменяют глубину. Как следствие из всего этого, системы стерео зрения имеют высокое разрешение глубины только в случае объектов, расположенных неподалеку от камеры (рисунок 12-5).

![Рисунок 12-5 не найден](Images/Pic_12_5.jpg)

Рисунок 12-5. Глубина и различия связаны обратно пропорционально, поэтому измерения глубины ограничиваются близлежащими объектами

До этого уже были показаны многие системы координат в рамках обсуждения процесса калибровки в главе 11. На рисунке 12-6 показаны двух и трех мерные системы координат, используемые в OpenCV для стерео зрения. При этом стоит обратить внимание на тот факт, что это правые системы координат: если направить указательный палец правой руки вдоль оси X, а средний палец правой руки согнуть в направлении оси Y, то большой палец будет указывать в направлении основного луча. Пиксели левого и правого изображения фотоприёмников представлены на рисунке в верхнем левом углу и обозначаются координатами ![Формула 12-13 не найдена](Images/Frml_12_13.jpg), соответственно. Центры проекции ![Формула 12-8 не найдена](Images/Frml_12_8.jpg) с основными лучами пересекают плоскость изображения в основной точке (не центре) ![Формула 12-14 не найдена](Images/Frml_12_14.jpg). После математических исправлений, камеры становятся выровненными по строкам (компланарными и горизонтально выровненными) и отдаленными друг от друга на расстояние *T* и с фокусным расстоянием *f*.

![Рисунок 12-6 не найден](Images/Pic_12_6.jpg)

Рисунок 12-6. Системы координат, используемые в OpenCV для неискаженных выпрямленных камер: координаты пикселей относительно верхнего левого угла изображения и две выравненные плоскости; координаты камеры относительно центра проекции левой камеры

При таком расположении относительно легко найти расстояние. Теперь необходимо приложить немного усилий для понимания того, как сопоставить настройки геометрии камеры в реальном времени. В реальном мире камеры почти никогда не выровнены точно фронтально параллельно (рисунке 12-4). Вместо этого, необходимо математически рассчитать проекции изображения и карты искажений, которые поправят левое и правое изображения до фронтально параллельного расположения. При проектировании стерео устройства лучше всего расположить камеры примерно фронтально параллельно и, насколько это возможно, горизонтально выровнено.  Физические преобразования благоприятно сказываются на математических вычислениях. Если камеры не выровнены хотя бы приблизительно, то в результате математического выравнивания может быть получено крайне искаженное изображение, тем самым снизиться или пропадет зона стерео перекрытия в конечном изображении. Для получения хорошего результата так же необходимо синхронизировать камеры. Если это не выполняется, то будут возникать проблемы при появлении движений в сцене (в том числе самих камер).

Рисунок 12-7 отражает реальную ситуацию между двумя камерами и необходимое математическое выравнивание. Для выполнения математического выравнивания необходимо больше информации о геометрии представления сцен двух камер. После получения данной геометрии и некой терминологии и обозначений, можно вернуть к проблеме выравнивания.

![Рисунок 12-7 не найден](Images/Pic_12_7.jpg)

Рисунок 12-7. Целью данного изображения является показать, как математически (а не физически) совместить две камеры в одном представлении плоскости так, что пиксели строк между камерами в точности выровнены друг относительно друга

### Эпиполярная геометрия

В основе геометрии системы компьютерного зрения лежит *эпиполярная геометрия*. В сущности, эта геометрия сочетает в себе две модели камеры обскуры (по одной для каждой камеры) и некоторые интересные новые точки, именуемые как *керновые точки* (рисунок 12-8). Перед объяснением того, чем хороши эти точки, будет рассмотрен процесс их определения и добавлена связанная с ними терминология. После всего этого, будет краткое общее понимание этой геометрии, а также значительно сужен набор точек соответствующих двум камерам. На практике это дополнение очень важное.

![Рисунок 12-8 не найден](Images/Pic_12_8.jpg)

Рисунок 12-8. Эпиполярная плоскость определяется наблюдаемой точкой P и двумя центрами проекции ![](); керновые точки располагаются в точках пересечения линии, соединяющая центры проекции и две проекционные плоскости

Для каждой камеры имеется отдельный центр проекции ![]() и пару соответствующих проекционных плоскостей ![](). Точка P материального мира проецируется на каждую из проекционных плоскостей ![](). Наибольший интерес представляют новые точки – керновые точки. Керновая точка ![]() (![]()) на плоскости ![]() (![]()) определяется как центр проекции изображения другой камеры ![]() (![]()). Плоскость пространства, образованная фактическими представлениями точки P и двумя керновыми точками ![]() и ![]() (или, что эквивалентно, двумя центрами проекции ![]()), именуется *эпиполярной плоскостью*, а линии ![]() и ![]() (от точки проекции до соответствующей эпиполярной точки) *эпиполярными линиями*.

Для осознания того, насколько полезна эпиполярность, необходимо вспомнить следующий факт: на самом деле точка материального мира, проецирующая на правую (или левую) плоскость изображения, может быть расположена в любом месте вдоль всей линии точек луча, идущего от ![]() через ![]() (или от ![]() через ![]()), т.к. для одной из камер не известно расстояние до рассматриваемой точки. Например, имеется точка P, которую видно на правой камере. Т.к. камера видит только ![]() (проекцию P на ![]()), по факту точка P может быть расположена в любом месте на линии, образованной ![]() и ![](). Очевидно, что эта линия содержит P, но она так же содержит и другие точки. Однако, что интересно, как выглядит проекция этой линии на левой плоскости изображения ![](); по факту это эпиполярная линия, определяемая ![]() и ![](). Изображение все возможных *точек*, отображенных на одном фотоприёмнике, это *линия*, проходящая через соответствующую точку и керновые точки другого фотоприёмника.

Краткий список некоторых фактов об эпиполярной геометрии стереокамер (и почему этому уделено внимание).

* Каждая трехмерная точка представлений камер располагается на эпиполярной плоскости, которая пересекает каждое изображение по эпиполярной линии.

* Учитывая особенности одного изображения, соответствующее представление другого изображения *должно* лежать вдоль соответствующей эпиполярной линии. Это известно как *эпиполярное ограничение*.

* Эпиполярное ограничение означает, что возможно преобразовать двумерный поиск для сопоставления особенностей двух фотоприёмников в одномерный поиск вдоль эпиполярных линий при условии наличия знаний о геометрии стереоустановки. Это не только огромное сокращение операций вычисления, но и отбрасывание из рассмотрения точек, которые могли бы привести ложным соответствиям.

* Порядок сохранения. Если точки A и B видны на обоих изображениях и горизонтально попадают в указанном порядке на один фотоприёмник, то они горизонтально попадают в указанном порядке т на другой фотоприёмник. (Из-за преград и областей перекрытия представления, важно, чтобы обе камеры не видели одни и те же точки. Тем не менее, порядок должен поддерживаться. Так, если точки A, B и C располагаются слева направо на левом фотоприёмнике и если B не видно на правом фотоприёмнике из-за наличия перекрытия, то правый фотоприёмник по-прежнему должен видеть точки A и C слева направо.)

### Существенная и фундаментальная матрицы

Осталось рассмотреть ещё два ингредиента, прежде чем переходить к функциям OpenCV, которые вычисляют эпиполярные линии. Это существенная матрица E и фундаментальная матрица F. Матрица E содержит информацию о перемещении и вращении двух связанных камер в материальном пространстве (рисунок 12-9), а F содержит такую же информацию, как и E плюс информацию о внутренних параметрах, относящихся к двум камерам в пиксельных координатах. Т.к. F содержит информацию о внутренних параметрах, то связь между двумя камерами выражается в пиксельных координатах.

![Рисунок 12-9 не найден](Images/Pic_12_9.jpg)

Рисунок 12-9. В основе геометрии стерео зрения лежит захват существенной матрицы E, содержащей всю информацию о перемещении T и вращении R, которые описывают положение второй камеры относительно первой в глобальных координатах

Существенная матрица E является чисто геометрической, при этом ничего не знающая о фотоприёмнике. Она сопоставляет расположение, в материальных координатах, точки P в одной точке, в чём можно убедиться при просмотре этой точки с левой и правой камер (т.е. связь ![]() к ![]()). Фундаментальная матрица F связывает точки плоскости изображения одной камеры в координатах изображения (в пикселях) с точками плоскости изображения другой камеры в координатах изображения (в дальнейшем будут использоваться обозначения ![]() и ![]()).

**Математика для существенной матрицы**

Пусть имеется точка P и необходимо получить соотношение, соединяющее отслеживаемые положения ![]() и ![]() точки P на двух фотоприёмниках. Эта связь служит оберткой определения существенной матрицы. Для начала будет рассмотрена связь между ![]() и ![](), при этом материальное расположение точки будет рассматриваться в координатах двух камер. Эта связь может быть представлена при помощи эпиполярной геометрии, как уже было показано ранее. (При этом не стоит путать ![]() и ![](), которые являются точками на проекционной плоскости изображения, с ![]() и ![](), которые являются положениями точки P в системе координат двух камер.)

Теперь необходимо выбрать один набор координат, левый или правый, для работы и выполнения расчетов. Пусть выбор падет на координаты сосредоточенные на ![]() левой камеры. Согласно этим координатам положение отслеживаемой точки будет ![](), а начальное положение другой камеры располагается на расстоянии T. Точка P, как видно на правой камере ![](), имеет координаты этой камеры, где ![](). Ключевым шагом является введение эпиполярной плоскости, которая как уже известно связывает все эти вещи. Конечно возможно представить плоскость множеством способов, но для рассматриваемого случая необходимо вспомнить, что уравнение для всех точек **x** на плоскости с нормальным вектором **n**, проходящим через точку **a**, необходимо соблюдать следующее ограничение:

![]()

Эпиполярная плоскость содержит векторы ![]() и T; таким образом, если есть перпендикулярный (векторное произведение векторов дает третий вектор, ортогональный к двум первым; направление определяется "правилом правой руки": если указательный палец соответствует направлению *a*, а средний палец направлению *b*, то векторное произведение *axb* перпендикулярно к *a* и *b* и соответствует направлению большого пальца) к обоим векторам вектор (например ![]()xT), то можно использовать его в **n** уравнениях плоскости. Так, уравнение для все возможных точек ![]() прохожящей через точку T и содержащей оба вектора имеет вид (за счет замены скалярного произведения на матричное перемножение транспанированного и нормального векторов):

![]()

Не стоит забывать, что оснавная цель заключается в том, чтобы связать ![]() и ![]() для начала в соотношении ![]() и ![](). Отрисовка ![]() на рисунке осуществляется за счет равенства ![](), которое для удобства лучше переписать следующим образом ![](). Выполнив подстановку и используя ![]() уравнение примет следующий вид:

![]()

Векторное произведение можно переписать в (несколько громоздкое) перемноженеи матриц. Таким образом матрица **S** примет следующий вид:

![]()

После подстановки уравненеи примет следующий вид:

![]()

*RS* - это существенная матрица E, тогда уравнение принимает компактный вид:

![]()

В результате получено связь между точками, которые наблюдаются на фотоприёмниках, но это только первый шаг. За счет выполнения замены при помощи проекционных уравнений ![]() и ![]() и последующего разделения на ![](), уравнение примет окончательный вид:

![]()

На первый взгляд может показаться, что уравнение определяется элементом *p*, если остальное известно, но E это обертка ранг-неполной матрицей (существенная матрица 3x3  ранга 2) и как следствие все заканчивается линейным уравнением. (Для квадратной nxn мтарицы E, ранг неполня оценка означает, что имеется менее чем n ненулевых собственных значения. В результате система линейных уравнений, указанных в ранг-неполной матрице, не имеет единственного решения. Если ранг (число ненулевых собственных значений) это n-1, то это будет строка, образованная набором точек, ккоторые все без исключения удовлетворяют системе уравнений. Система определяется матрицей ранга n-2, образуя плоскость, и так далее.) Существенная матрица содержит пять параметров - три для вращения и два для направленного перемещения (без установки масштаба) - и два ограничения: (1) определитель равен 0, т.к. это ранк-неполная матрица (3x3 с рангом 2); (2) два ненулевых сингулярных разложения равны, потому что матрица S кососимметричная, а R это матрица вращения. В общей сложности это даёт семь ограничений. При этом, ещё раз, не стоит путать данную E с внутренними параметрами E камеры; таким образом, связанные точки выржаются в материальных координатах или координатах камеры, а не в пиксельных координатах.

**Математика для фундаментальной матрицы**

Матрица E содержит всю информацию о геометрии двух камер относительно друг друга, но не о самих камерах. На практике, наибольший интерес вызывают пиксельные координаты. Для поиска связи между пикселем одного изображения и соответствующей эпиполярной линией другого изображения, необходимо ознакомиться с внутренней информацией о двух камерах. Для того, чтобы это сделать необходимо подставить вместо *p* (в пиксельных координатах) *q* и матрицу внутренних параметров камеры. *q = Mp* (где M - это матрица внутренних параметров камеры) или, что эквивалентно, ![](). В результате уравнение для E принимает следующий вид:

![]()

Это выглядит несколько беспорядочно, однако введение фундаментальной матрицы:

![]()

устраняет этот беспорядок

![]()

Вкратце: фундаментальная матрица F это существенна матрица E с той лишь разницей, что F работает с пиксельными координатами изображения, тогда как E работает с материальными координатами (при этом стоит обратить внимание на уравнение, связывающее фундаментальную и существенную матрицы; если выравнить изображение и нормализовать точки за счет деления на фокусное расстояние, то матрица внутренних параметров M становится единичной и тогда *F = E*). Матрицы E и F имеют ранг 2. Фундаментальная матрица содержит семь параметров, два для каждой эпиполярной точки и три для гомографии, которая связывает две плоскости изображения (как правило масштаб не влияет на четыре параметра).

**То, как обрабатывает все рассмотренные вещи OpenCV**

Можно вычислить F точно так же, как и гомографию изображения в предыдущем разделе за счет предоставления набора известных соответствий. В этом случае не требуется выполнять отдельную калибровку камеры, потому что можно найти решение непосредственно для F, которая неявно содержит фундаментальные матрицы обеих камер. Функция, выполняющая все эти вещи, именуется *cvFindFundamentalMat()*:

```cpp
	int cvFindFundamentalMat(
		 const CvMat* 	points1
		,const CvMat* 	points2
		,CvMat* 		fundamental_matrix
		,int 			method = CV_FM_RANSAC
		,double 		param1 = 1.0
		,double 		param2 = 0.99
		,CvMat* 		status = NULL
	);
```

Первые два аргумента это вещественные указатели (одинарной точности) Nx2 или Nx3 матрицы, содержащие соответствующие собранные N точки (это так же могут быть N-1 многоканальные матрицы с двумя или тремя каналами). Результирующая матрица ** должна быть матрицей 3x3 той же точностью, что и точки (в частности размерность может быть 9x3).

Следующий аргумент определяет метод, который будет использоваться при вычислении фундаментальной матрицы по соответствующим точкам; может принимать одно из четырех значений. Для каждого значения есть определенное ограничение по количеству необходимых (или разрешенных) точек в *points1* и *points2*, как показано в таблице 12-2.

Таблица 12-2. Ограничения на аргумент метода

| Значение метода | Количество точек | Алгоритм |
| -- | -- | -- |
| CV_FM_7POINT | N = 7 | Семи-точечный алгоритм |
| CV_FM_8POINT | N ≥ 8 | Восьми-точечный алгоритм |
| CV_FM_RANSAC | N ≥ 8 | Алгоритм RANSAC |
| CV_FM_LMEDS | N ≥ 8 | Алгоритм LMedS |

Семи-точечный алгоритм задействует ровно семь точек, а так же тот факт, что матрица F имеет ранг 2 для полного ограничения матрицы. Преимущество этого ограничения в том, что F всегда имеет ранг 2, поэтому не имеет очень малое собственное число, близкое к 0. Недостатком является то, что это ограничение не является абсолютно уникальным и потому результирующая матрица может быть трех экземпляров (в этом случае *fundamental_matrix* должна быть матрицей 9x3, что бы вместить все три варианта). Восьми-точечный алгоритм находит F в виде линейной системы уравнений. Если задействуются более 8 точек, то возникающие ошибки устраняются по методу наименьших квадратов совместно с минимизацией всех точек. Проблема семи-точечного и восьми-точечного алгоритмов в том, что они чрезвычайно чувствительны к выбросам (даже, если имеется более восьми точек в случае с восьми точечным алгоритмом). Алгоритмы *RANSAC* и *LMedS* как правило классифицируются как надежные методы, потому что они способны распознавать и удалять выбросы. () Для каждого алгоритма важно иметь более восьми точек.

Следующие два аргумента - это параметры, используемые только *RANSAC* и *LMedS*. Первый *param1* - это максимальное расстояние от точки до эпиполярной линии (в пикселях), за пределами которой точка считается выбросом. Второй параметр *param2* является желаемым доверительным интервалом (значение между 0 и 1), который по существу сообщает алгоритму количество итераций.

Последний аргумент *status* не обязателен; если используется, то это должна быть матрица Nx1 типа *CV_8UC1*, где N соответствует *points1* и *points2*. Если эта матрица не NULL, то *RANSAC* и *LMedS* используют данную матрицу для хранения информации о том, какие точки являются выбросами, а какие нет. В частности, соответствующая запись будет установлена в 0, если точка является выбросом и в 1 в противном случае.

Возвращаемое значение - это целое число, указывающее на количество найденных матриц. Это будет 1 или 0 для всех случаев, кроме семи-точечного алгоритма, где так же возможно значение 3. Значение 0 указывает на невозможность вычисления матрицы. Ниже представленный пример, взятый из руководства по OpenCV, поможет окончально разобраться с этой функцией.

Пример 12-2. Вычисление фундаментальной матрицы при помощи RANCAS

```cpp
int 	point_count = 100;
CvMat* 	points1;
CvMat* 	points2;
CvMat* 	status;
CvMat* 	fundamental_matrix;

points1 = cvCreateMat( 1, point_count, CV_32FC2 );
points2 = cvCreateMat( 1, point_count, CV_32FC2 );
status = cvCreateMat( 1, point_count, CV_8UC1 );

/* Заполнение точек ... */
for( int i = 0; i < point_count; i++ ) {
	points1->data.fl[i*2] 		= <x1, i>;
	points1->data.fl[i*2+1] 	= <y1, i>;
	points2->data.fl[i*2] 		= <x2, i>;
	points2->data.fl[i*2+1] 	= <y2, i>;
}

fundamental_matrix = cvCreateMat( 3, 3, CV_32FC1 );
int fm_count = cvFindFundamentalMat(
	 points1
	,points2
	,fundamental_matrix
	,CV_FM_RANSAC
	,1.0
	,0.99
	,status
);
```

Пару слов предупреждений - связанных с возвращением 0 - алгоритмы могут быть провальными, если точки поставляются в *вырожденной форме*. Вырожденная форма возникает тогда, когда поставлемые точки предоставляют меньше информации, чем требуется, например, когда одна точка повторяется более одного раза или когда несколько точек коллинеарны или компланарны с чересчур многими другими точками. Важно всегда проверять возвращаемое значение *cvFindFundamentalMat()*.

### Вычисление эпиполярных линий

Теперь, имея фундаментальную матрицу, появляется возможность для вычисления эпиполярных линий. Функция OpenCV *cvComputeCorrespondEpilines()* вычисляет для списка точек одного изображения эпиполярную линию на другом изображении. При этом стоит отметить, что по любой заданной точке одного изображения существует соответствующая эпиполярная линия другого изображения. Каждая вычисляемая линия кодируется в виде вектора из трех точек (a, b, c), который определяется следующим уравнением:

![]()

Для вычисления эпиполярных линий, функция запрашивает фундаментальную матрицу, которая вычисляется в *cvFindFundamentalMat()*.

```cpp
	void cvComputeCorrespondEpilines(
		 const CvMat* 	points
		,int 			which_image
		,const CvMat* 	fundamental_matrix
		,CvMat* 		correspondent_lines
	);
```

Первый аргумент *points*, как правило, Nx2 или Nx3 массив точек (который может быть Nx1 многоканальным массивом с двумя или тремя каналами). Аргумент ** может быть либо 1, либо 2 и указывает на то, какие точки определяются на изображении (относительно массивов *points1* и *points2* функции *cvFindFundamentalMat()*). *fundamental_matrix* это матрица 3x3, возвращаемая *cvFindFundamentalMatrix()*. *correspondent_lines* является массивом вещественных чисел Nx3, в который записывается результат. Легко заметить, что уравнение линии ax + by = c = 0 не зависит от общей нормализации параметров a, b и c. По умолчанию они нормированы так, что ![]().

### Стерео калибровка

Уже было рассмотрено достаточно теории и техник, касаемых камер и трехмерных точек, для рассмотения стерео калибровки (в этом разделе) и стерео исправления (в следующем разделе). *Стерео калибровка* - это процесс вычисления геометрической связи между двумя пространствами камер. В отличии от этого *стерео исправления* - это процесс *исправления* отдельно взятых изображений так, чтобы казалось будто бы они взяты от двух камер с выравненными плоскостями изображения (рисунок 12-4 и 12-7). При таком исправлении, оптические оси (или основные лучи) двух камер параллельны и потому они пересекаются в бесконечности. Можно было бы конечно калибровать две камеры иначе, но в данном случае (и в OpenCV) используется более общий и простой случай установки основных лучей, пересекающихся в бесконечности.

Стерео калибровка зависит от матрицы вращения R и вектора перемещения T между двумя камерами, как показано на рисунке 12-9. И R и T вычисляется функцией *cvStereoCalibrate()*, схожая с *cvCalibrateCamera2()*, которая была рассмотрена в главе 11, за исключением того, что теперь имеется две камеры и новая функция может вычислить (или использовать какие-либо предварительные вычисления) для камеры искажения существенной или фундаментальнйо мтарицы. Другое отличие стерео калибровки от калибровки одной камеры в том, что в *cvCalibrateCamera2()* используется законченные список вращения и вектор перемещения между камерой и представлением шахматной доски. В случае с *cvStereoCalibrate()* ищется одна матрица вращения и один вектор перемещения, которые связывают правую и левую камеры.

Уже было показано, как вычислять существенную и фундаментальную матрицы, однако не было показано как вычислять R и T, связывающие левую и правую камеры. Для любой заданной трехмерной точки P в координатах объекта можно отдельно использовать единичную калибровку для двух камер для перевода P в координаты камеры ![]() и ![]() для левой и правой камер, соответственно. Из рисунка 12-9 так же видно, что два представления P (от двух камер) можно связать уравнением ![](), где R и T матрица вращения и вектор перемещения между камерами, соответственно. Имея эти три уравнения получаем решение для матрицы вращения и вектора перемещения по отдельности:

![]()

![]()

Имея множество совместных представлений углов шахматной доски, *cvStereoCalibrate()* использует *cvCalibrateCamera2()* чтобы найти решение для параметров матрицы вращения и вектора перемещения представления шахматной доски для каждой камеры в отдельности (глава 11, раздел "Что под капотом?"). Затем найденные решения подставляются в ранее рассмотренные уравнения для нахождения мтарицы вращения и вектора перемещения между двумя камерами. Из-за присутствия шума в изображении и ошибок округления каждая шахматная доска попарно объединяет различия в значениях для R и T. Функция *cvStereoCalibrate()* принимает найденные средние значения R и T в качестве начального приближения для поиска истинных значений за счет использования надежного *Levenberg-Marquardt* итеративного алгоритма поиска (локального) минимума ошибки перепроецирования углов шахматной доски для обоих представлений камер и возвращает решение для R и T. Итак, чтобы было ясно, что дает стерео калибровка: матрица вращения размещается в правой камере в той же плоскости, что и в левой камере; это объединяет две плоскости в одну не выровненную плоскость (выравнивание будет рассматриваться в следующем разделе "Стерео исправления").

Функция *cvStereoCalibrate()* имеет много параметров, но они все довольно таки просты и к тому же многие схожи с параметрами функции *cvCalibrateCamera2()* из главы 11.

```cpp
	bool cvStereoCalibrate(
		 const CvMat* 		objectPoints
		,const CvMat* 		imagePoints1
		,const CvMat* 		imagePoints2
		,const CvMat* 		npoints
		,CvMat* 			cameraMatrix1
		,CvMat* 			distCoeffs1
		,CvMat* 			cameraMatrix2
		,CvMat* 			distCoeffs2
		,CvSize 			imageSize
		,CvMat* 			R
		,CvMat* 			T
		,CvMat* 			E
		,CvMat* 			F
		,CvTermCriteria 	termCrit
		,int 				flags = CV_CALIB_FIX_INTRINSIC
	);
```

Первый параметр *objectPoints* это матрица Nx3, содержащая материальные координаты каждой из K точек на каждом M изображении трехмерного объекта таким образом, что N = KxM. Когда используется шахматная доска как трехмерный объект, эти точки находятся в системе координат, связанной с объектом - при установки необходимо сообщить, что левый верхний угол шахматной доски является исходным (и, как правило, выбранный так, что бы координата Z была равна 0), при этом какие-либо известные трехмерные точки могут быть использованы, как описано в *cvCalibrateCamera2()*.

Для разграничения одинаковых по смыслу параметров двух камер параметры оканчиваются на "1" и "2". В результате, следующие параметры *imagePoints1* и *imagePoints2* - это матрицы Nx2, содержащие левые и правые координаты пикселей (соответственно) всех опорных точек объекта из *objectPoints*. Если выполнить калибровку при помощи шахматной доски для двух камер, то *imagePoints1* и *imagePoints2* это соответственно возвращаемые значения для M, которые получаются после вызова **imagePoints1* и *imagePoints2** для левого и правого представления камер.

Аргумент *npoints* содержит число точек для каждого изображения и является матрицей Mx1.

Параметры *cameraMatrix1* и *cameraMatrix2* это матрицы проекций камер 3x3, а *distCoeffs1* и *distCoeffs2* это матрицы искажения 5x1 для 1 и 2 камер, соответственно. При этом два параметра радиальных искажений содержаться в первой матрице, а два параметра тангенциального искажения и два радиальных искажений во второй (глава 11, коэфициенты искажения). Три параметра радиальных искажений завершают матрицу, т.к. были добавлены по ходу развития OpenCV; эти параметры, как правило, используются в случае с широкоугольными (с эффектом рыбий глаз) объективами. Использование матриц внутренних параметров камер контролируется параметром *flags*. Если *flags = CV_CALIB_FIX_INTRINSIC*, то эти матрицы используются в процессе калибровки. Если *flags = CV_CALIB_USE_INTRINSIC_GUESS*, то эти матрицы используются в качестве отправной точки по оптимизации матриц внутренних параметров и искажений для каждой камеры и будут установлены в более точные значения после выполнения *cvStereoCalibrate()*. Другие значения параметра *flags*, которые соответствуют аналогичному параметру функции *cvCalibrateCamera2()*, можно аддитивно объединить; в этом случае эти параметры будут вычисляться с нуля в *cvStereoCalibrate()*. Т.е. можно вычислить матрицу внутренних параметров, матрицу внешних параметров и стерео параметры за один проход функцией *cvStereoCalibrate()*.

Параметр *imageSize* - это размер изображения в пикселях. Используется только если необходимо уточнить или вычислить внутренние параметры, когда *flags != CV_CALIB_FIX_INTRINSIC*.

Элементы R и T - это выходные параметры, которые заполняются функцией и которые являются матрицей вращения и вектором перемещения (связывающие левую и правую камеры), соответственно. Парамтеры E и F являются необязательными. Если они не установлены в NULL, то функция будет вычислять и заполнять их 3x3 существенной и фундаментальной матрицами. Параметр *termCrit* ранее уже был неоднократно рассмотрен. Он отвечает за внутреннюю оптимизацию за счет сообщения о прекращении после определенного числа итераций или когда вычисляемые параметры становятся меньше заданного порога в структуре *termCrit*. Типичный пример использования данного параметра выглядит следующим образом: *cvTermCriteria(CV_TERMCRIT_ITER + CV_TERMCRIT_EPS, 100, 1e-5)*.

И в заключении, параметр *flags*, о котором уже было сказано пару слов ранее. Если камеры откалиброваны и результат внушает доверие, то можно "закрепить неподвижно" результаты калибровки одной из камер при помощи *CV_CALIB_FIX_INTRINSIC*. Если начальные результаты калибровки хорошие, но не замечательные, то можно выполнить уточнение внутренних параметров и параметров искажения при помощи *CV_CALIB_USE_INTRINSIC_GUESS*. Если раздельная калибровка камер не выполнялась, то можно использовать те же настройки параметра *flags*, что и в *cvCalibrateCamera2()* главы 11.

После получения матрицы вращения и вектора перемещения (R, T) или фундаментальной матрицы F, можно их использовать для исправления двух стереоизображений таким образом, чтобы эпиполярные линии расположились вдоль строк изображений, а линии сканирования были одинаковыми на обоих изображениях. Несмотря на то, что R и T не определяют уникальность стерео исправлений, в следующем разделе будет показано как их (совместно с другими ограничениями) можно использовать.

### Стерео исправления

Легче всего вычислить стерео несоответствия, когда обе плоскости изображения точно выровнены (рисунко 12-4). К сожалению, как уже было сказано ранее, редко удаеться добиться точно выравнивания в реальной стерео системе, т.к. две камеры почти никогда не имеют точно компланарные, построчно-выровненные плоскости изображений. На рисунке 12-7 показана цель стерео исправлений: необходимотсь перепроецирования плоскостей изображения двух камер так, чтобы они находились точно в одной и той же плоскости с совершенно выравненными строками во фронтально-параллельной форме. Возникает вопрос, как выбрать конкретную плоскость, в которой математическое выравнивание камеры зависит от используемого алгоритма? В дальнейшем будут показаны два случая, используемые в OpenCV.

Необходимо, чтобы строки изображения между двумя камерами были выровнены после испарвлений так, чтобы стерео соответствия (поиск одной и то же точки на двух различных представлениях камеры) были более надежными и лекго вычисляемыми. Надежность и эффективность вычислений можно повысить за счет выполнения поиска только по одной строке для сопоставления с точкой другого изображения. Результатом выравнивания горизонтальных строк в пределах общей плоскости изображения, которую содержит каждое изображение, является то, что керновые точки перемещаются в бесконечность. Т.е. изображение центра проекциии одного изображения параллельно другой плоскости изображения. Но т.к. имеет место бесконечное число возможных фронтально-параллельных плоскостей для выбора, то необходимо большее количество ограничений: максимизацию перекрывающих представлений и/или минимизацию искажений, выбор которых зависит от используемого алгоритма.

Результатом выравнивания двух плоскостей изображения является восемь элементов, по четыре для каждой камеры. Для каждой камеры вычисляется вектор искажений *distCoeffs*, матрица вращения ![]() и выравненная и неочищенная матрицы (![]() и M, соответственно). Благодаря этим элементам можно построить карту при помощи *cvInitUndistortRectifyMap()*, где применяется интерполяция пикселей исходного изображения для создания нового исправленного изображения. (Стерео исправления в OpenCV возможны только тогда, когда эпиполярные точки находятся за пределами изображения прямоугольника. Следовательно алгоритмы исправления могут не работать со стееро конфигурацией, которые характеризуются либо очень широкими базисными линиями, либо когда камеры указывают друг на друга в значительной степени).

Есть множество путей вычисления элементов исправления, но OpenCV использует только два: (1) алгоритм Hartley, который на выходе дает неоткалиброванное стерео за счет использования только фундаментальной матрицы; (2) алгоритм Bouguet, который использует параметры вращения и перемещения от двух откалиброванных камер. Алгоритм Hartley может быть использован для получения структуры движения, записанного одной камерой, но вместе с тем может (при стерео исправлениях) привести к появлению большего количества искаженных изображений, чем откалиброванный алгоритм Bouguet. В ситуациях, когда возможно использование откалиброванных образцов - такие, как рука робота или камера безопастности - наиболее естественно использование алгоритма Bouguet.

**Неоткалиброванное стерео исправление: алгоритм Hartley**

Алгоритм Hartley пыается найти гомографии, отображающие эпиполярные точки в бесконечности и своядящие к минимуму расчетные несоответствия между двумя стерео изображениями; это достигается за счет сопоставления точек между двумя парами изображения. Таким образом, необходимость в вычислении внутренних параметров камеры отпадает, т.к. эта информация в неявном виде содержится в сопоставлениях. Следовательно необходимо вычисленить только фундаментальную матрицу, которая может быть получена от любого набора сопоставлений из семи или более точек между двумя представлениями сцены за счет *cvFindFundamentalMat()*. Как вариант, фундаментальная матрица может быть вычисленна при помощи *cvStereoCalibrate()*.

Преимущество от использования алгоритма Hartley заключается в том, что стерео калибровка в реальном времени может быть выполнена за счет наблюдения только за точками сцены. Недостаток заключается в том, что отсутствует чувствительность к изменению масштаба изображения. Например, если использовать шахматную доску для генерации точек сопоставления, то не имеется возможности сказать далеко (если доска размера 100 метров) или близко (если доска размера 100 см). Так же не имеется явного определения матрицы внутренних параметров без которой камеры могут иметь разные фокусные расстояния, перкошенные пиксели, различные центры проекций и/или различные основные точки. Как результат, можно определить трехмерные объекты реконструировав только проекционные преобразования. Это означает, что различные масштабы или проекции объекта могут показаться одним и тем же (т.е. особые точки имеют одинаковые двумерные координаты при различных трехмерных объектов). Обе проблемы показаны на рисунке 12-10.

