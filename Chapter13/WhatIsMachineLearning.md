# Машинное обучение

## (П]|(РС)|(РП) Что такое машинное обучение

Целью *машинного обучения (ML)* является преобразование данных в информацию. После изучения набора данных, у машин появляется возможность ответить на вопросы о данных: Какие данные наиболее близки к имеющимся данным? Присутствует ли автомобиль на изображении? На какую рекламу будут реагировать пользователи? Наиболее часто используемой компонентой является стоимость, соответственно возникает следующий вопрос: "Какой продукт, из имеющегося набора, с наивысшей стоимостью будет выбран пользователем при показе рекламы?" Машинное обучение преобразует данные в информацию, извлекая правила и шаблоны из этих данных.

Тема машинного обучения является довольна таки обширной. OpenCV в основном занимается статистикой, а не такими вещами, как "Байесовская сеть", "Марковское случайное поле" или "графические модели". Довольно таки хорошие статьи по данной теме можно найти у: Hastie, Tibshirani, и Friedman; Duda и Hart; Duda, Hart, и Stork; и Bishop. Для того, как распараллелить машинное обучение можно изучить работы Ranger et al. и Chu et al.

### Обучение и тестирование

Машинное обучение работает с такими данными, как температурные значения, цены на акции, интенсивность окраски и т.д. Зачастую данные предварительно перерабатываются в особенности. Можно, например, имея базу данных из 10000 изображений лица, запустить определитель контура лица на этих лицах с целью накопления таких особенностей, как постановка и четкость контура, для определения центра лица для каждого лица в отдельности. В результате можно получить, например, 500 таких значений/лиц или вектор особенностей с 500 записями. Таким образом, методы машинного обучения могут быть использованы для построения своего рода модели по данному набору данных. Если же необходимо только сгруппировать лица (широкие, узкие и т.д.), то лучше всего использовать *алгоритм кластеризации*. Если же необходимо научиться предсказывать возраст человека по шаблону контура лица или лица в целом, то лучше всего использовать *алгоритм классификации*. Для достижения всех этих целей, алгоритмы машинного обучения анализируют набор особенностей и регулируют соответствующие веса, пороги и другие параметры для получения наилучшего результата. Этот процесс корректировки параметров для удовлетворения цели именуется *обучением*.

Всегда важно знать, как работают методы машинного обучения, к тому же это может быть довольно таки "ювелирной" работой. Как правило, исходный набор данных разбивается на большую выборку для обучения (например, 9000 лиц из ранее рассмотренного примера) и на малую выборку для тестов (из оставшихся 1000 лиц). Далее можно запустить классификатор по выборке для обучения с целью получения модели прогнозирования возраста по полученному вектору особенностей. В заключение можно протестировать полученный классификатор на оставшейся выборке для тестов.

Выборка для тестов не используется в обучении. Классификатор запускается на каждом лице (всего 1000 лиц) из выборки для тестов с последующей фиксацией того, насколько хорошее предсказание получается при сопоставлении полученного варианта возраста с реальным показателем возраста. Если классификатор работает плохо, то можно попробовать добавить новые особенности или рассмотреть другой тип классификатора. Далее в данной главе будут рассмотрены некоторые виды классификаторов и алгоритмы для их обучения.

Если классификатор хорошо справляется с поставленной задачей, то можно судить о получении потенциально ценной модели, которая может быть использована на реальных данных. Возможно использование полученной системы для установки режима в видеоигре в соответствии с возрастом. Перед игрой, его или её лицо обрабатывается для получения 500 (постановка и четкость контура, центр лица) особенностей. Затем эти данные передаются в классификатор; возвращаемое значение возраста приводит в установке соответствующего поведения в игре. Пр иразвертывание модели, классификатор рассматривает лица, которые не видел ранее и принимает решение в соответствии с тем, что узнал по выборке для обучения.

В заключении, зачастую, при развертывании системы классификации, задействуется набор данных для проверки. Иногда испытывание системы в конце это слишком трудоёмкая задача. Зачастую требуется настроить параметры именно перед отправкой классификатора на окончательнео тестирование. Сделать это можно, разбив исходное множество данных о 10000 лиц на три части: на выборку для обучения из 8000 лиц, на выборку для проверки из 1000 лиц и на выборку для тестирвоания из 1000 лиц. Теперь при запуке классификатора на выборке для обучения, можно "в фоновом режиме" пройтись и по выборке для проверки. И только после подтверждения верности проделанной работы на выборке для проверки можно будет запустить классификатор на выборке для тестирования для получения окончательного решения.

### Контролируемые и неконтролируемые данные

Иногда данные не имеют меток; все что требуется, это просто посмотреть каким образом можно сгруппировать лица, основываясь на информации о крае. А иногда данные имеют метки, например, такую, как возраст. В случае с машинным обучением это означает, что обучение может быть *контролируемым* (т.е. используется обучение "сигнала" или "метки", поступающие от вектора особенностей). Если вектор данных немеченный, то машинное обучение *неконтролируемое*.

Контролируемое обучение может быть *категоричным*, т.к. обучение ассоциируется с именованием лиц, или данные могут быть *пронумерованы* или *упорядочены* метки, такие как возраст. Когда данные проименованны (категоричны) как метки, то можно сказать, что выполнена *классификация*. Когда данные пронумерованы, то можно сказать, что выполнена *регрессия*.

Контролируемое обучение сопряжено с преобразованиями в оттенки серого. При таком виде обучения используется попарное сопоставление один к одному меток на векторах данных; в добавок к этому может быть использовано *отложенное обучение* (иногда так же именуемое как *подкрепленное обучение*). В подкрепленном обучении, метка данных (так же именуемая *наградой* или *наказанием*) может быть получена намного позже после исследования искомого вектора данных предмета наблюдения. Например, в случае перемещения мыши по лабиринту в поисках пищи, она может сделать несколько кругов, прежде чем найдет пищу, т.е. вознаграждение. В свою очередь, это вознаграждение должно каким-то образом оказать влияние на все предыдущие мнения и действия, которые совершила мышь в процессе поиска еды. Подкрепленное обучение работает аналогичным образом: система получает сигнал с задержкой (награду или наказание) и пытается предсказать поведение для будущих запусков (способ принятия решений; например, в какую сторону идти в лабиринте на каждом последующем шаге). Контролируемое обучение может так же использовать частичную маркировку, т.е. некоторых меток не хватает (это так называемое *полу контролируемое обучение*), или шумовые метки, т.е. некоторые метки ошибочны. Большинство алгоритмов машинного обучения обрабатывают только одну или две из описанных ситуаций. Например, алгоритмы машинного обучения могут выполнить классифицикацию, но не могут выполнить регрессию; алгоритм в состоянии выполнить полуконтролируемое обучение, но не подкрепленное обучение; алгоритм в состоянии иметь дело с числовыми данными, но не с категоричными; и так далее.

На самом деле приходиться иметь дело с немеченными данными и проверкой естественности попадания данных в группы. Алгоритмы, использующие неконтролируемое обучение, именуются *алгоритмами кластеризации*. В этом случае, цель заключается в группировке немеченных данных, которые "закрыты". В простом случае может возникнуть необходимость просто посмотреть, как распределяются лица: Какие из них тонкие или широкие, длинные или короткие? Например, рассматривая данные, поступающие от рака, как необходимо кластеризовать различные виды раков на группы, имеющие различные химические сигналы? Неконтролируемые кластеризованнные данные зачастую используются при формировании вектора особенностей для высокоуровневых контролируемых классификаторов. Для начала можно сформировать кластер лиц по типу лица (широкие, узкие, длинные, короткие), а затем использовать его в качестве исходных данных для обработки других данных, например, таких, как набор средних вокальных частот для предсказания пола человека.

Эти две общие задачи машинного обучения, классификация и кластеризация, пересекаются с двумя наиболее общими задачами в компьютерном зрении: распознаванием и сегментацией. Эти задачи иногда так же называют как "что" и "где". То есть, зачастую необходимо, чтобы компьютер назвал объекты на изображении (распознал или "что"), а так же указал место этого объекта (сегментация или "где"). Так в компьютерном зрении интенсивно используется машинное обучение, в OpenCV включено множество мощных алгоритмов машинного обучения в виде библитеки, расположенной в *../opencv/ml*.

	Код в OpenCV, отвечающий за машинное обучение, является обобщенным. Т.е. хотя этот код является полезным для задач компьютерного зрения, сам по себе код не спецефичен для компьютерного зрения. С его помощью, например, можно узнать геномные последовательности за счет соответствующих процедур. При этом основная задача сводится к управлению объектом, заданный вектором особенностей и полученный от изображения.

### Генеративные и Дискриминативные модели

Многие алгоритмы были разработаны для выполнения обучения и кластеризации. OpenCV поддерживает некоторые из наиболее полезные и доступные в настоящее время статистические подходы машинного обучения. Вероятностные подходы машинного обучения, такие как Байесовые сети или графические модели, менее хорошо поддерживаются в OpenCV прежде всего из-за того, что являются более новыми и до сих пор в стадии активного развития. OpenCV стремиться поддерживать *дискримитивные алгоритмы*, для которых характерна вероятность метки относительно данных (P(L|D)), а не *генеративные алгоритмы*, а не генеративные алгоритмы, для которых характерна вероятность данных относительно метки (P(D|L)). Хотя различия и не всегда понятны, дискриминативные модели хороши для высокопроизводительных прогнозов по заданным данным, в то время, как генеративные модели хороши для более мощного представления данных или для условного синтеза новых данных (имея "воображаемого" слона, можно сгенерировать данные по условию "слон").

Зачастую проще объяснить генеративную модель, т.к. эти модели являются причиной (правильных или неправильных) данных. Дискримитивное обучение зачастую сводится к принятию решения на основе некоторого порогового значения, которое может быть произвольным. Например, если предположить, что участок дороги определяется в сцене по большому счету потому, что составляющая "красного" цвета меньше 125. При этом возникает вопрос: будет ли участок, составляющая "красного" цвета которого равна 126, соответствовать дороге? Такого рода вопросы довольно таки трудно интерпретировать. В случае с генеративными моделями, как правило, приходиться иметь дело с условным распределениями данных по заданным категориям, что позволит развить чувство "близости" к полученному распределению.

### Алгоритмы машинного обучения в OpenCV

Алгоритмы машинного обучения, реализованные в OpenCV, приведены в таблице 13-1. Все эти алгоритмы находятся в библиотеке **ML**, за исключением *Mahalanobis* и *K-means*, которые находятся в **CVCORE**, и *face detection*, который располагается в **CV**.

Таблица 13-1. Алгоритмы машинного обучения, реализованные в OpenCV

| **Алгоритм** | **Описание** |
| -- | -- |
| Mahalanobis | Мера расстояния, рассчитываемая для "тягучего" пространства данных, деленного на ковариационные данные. Если ковариация является единичной матрицей (идентичная дисперсии), то эта мера совпадает с мерой Евклидова расстояния |
| K-means | Неконтролируемый алгоритм кластеризации, который представляет собой распределение данных с использованием K центров, где K задается пользователем. Разница между этим алгоритмом и expectation maximization заключается в том, что в этом алгоритме центры не гауссовы и как результат кластеры похожи на мыльные пузыри, т.к. центры (в силу) конкурируют за "владение" ближайшими точками данных. Эти кластерные области зачастую используются как разряженные гистограммы бинов для представления данных. Изобретен Steinhaus, использован Lloyd |
| Normal/Naïve Bayes classifier | Генеративный классификатор, в котором допускаются особенности с гауссовым распределением и статически независимые друг от друга, сильное предположение, как правило, не верно. По этой причине данный алгоритм зачастую называют "наивно Бейсовым" классификатором. Тем не менее этот метод зачастую работает на удивление хорошо |
| Decision trees | Дискриминационный классификатор. В дереве ищется одна особенность и пороговое значение текущего узла, которая наилучших образом разделяет данные на отдельные классы. Данные разделяются и данная процедура рекурсивно повторяется вниз слева направа по ветвям дерева. Не так часто результат можно получить на самой вершине дерева, однако, это первое, что необходимо попробовать сделать, т.к. это быстро и имеет высокую функциональность |
| Boosting | Группа дискриминативных классификаторов. Обобщенное классификационное решение получается за счет комбинирования взвешенных классификационных решений группы классификаторов. В ходе обучения изучается группа классификаторов (по одному за раз). Каждый классификатор из группы является "слабым" классификатором (с неким шансом на повышение производительности). Эти слабые классификаторы, как правило, состоят из единой переменной деревьев решений, называемой "stumps". В ходе обучения, найденный stump обучает решения классификатора, а так же определяет вес его "голоса". Между обучениями каждый классификатор, один за одним, повторно взвешивает точки так, что наибольшее внимание уделяется точкам, где были сделаны ошибки. Этот процесс продолжается до тех пор, пока суммарное значение ошибок, возникающих от комбинирования взвешиванных голосов дерева решений, на множестве данных не станет меньше установленного порога. Этот алгоритм зачастую является эффективным, когда доступен большой объём данных |
| Random trees | Дискриминативный лес множества деревьев решений, каждое из которых построено с большой или максимально расщепленной глубиной. В ходе обучения для каждого узла каждого дерева разрешено выбирать переменные расщепления только из случайного подмножества особенностей. Это гарантирует то, что каждое дерево становится статистически независимым в принятии решения. Во время применения, каждое дерево получает взвешенный голос. Этот алгоритм зачастую очень эффективен, а так же позволяет выполнять регрессию за счет усреднения выходных значений каждого дерева |
| Face detector / Haar classifier | Приложение, распознающее некий объект, базируется на основе разумного использования алгоритма boosting. OpenCV содержит алгоритм обучения определения лица, который на удивление работает хорошо. Алгоритм обучения так же можно применить на других объектов за счёт прилагаемого ПО. Данный алгоритм хорошо работает в случае твердых объектов и характерных представлений |
| Expectation maximization (EM) | Генеративный безконтрольный алгоритм, который используется для кластеризации. Ему соответствует N многомерных Гауссиан, где N задается пользователем. Данный алгоритм может быть эффективным способом представления более сложного распределения у которого только несколько параметров (средних значений и дисперсий). Зачастую используется в сегментации |
| K-nearest neighbors | Самый простой дискриминативный классификатор. Обучение состоит в простом сохранение меток. После этого контрольная точка классифицируется в соответствии с большинством голосов её ближайших K других точек (в евклидовом смысле близости). Это, скорее всего, самое простое, что можно сделать. Зачастую данный алгоритм является эффективным, но вместе с тем он медленно работает и требует много памяти |
| Neural networks / Multilayer perceptron (MLP) | Дискриминативный алгоритм, который (почти всегда) имеет "скрытые единицы" между выходными и входными узлами для наилучшего представления входного сигнала. Обучение может быть медленным, однако, во время применения очень быстрым. Тем не менее, главной областью применения является распознавание букв |
| Support vector machine (SVM) | Дискриминативный классификатор, который тоже может выполнять регрессию. Функция расстояния определяется между любыми двумя точками многомерного пространства. Алгоритм "узнает" разделенные гиперплоскости, которые максимально разделяют классы в верхнем измерении. Алгоритм стремиться быть в числе лучших на ограниченном наборе данных, проигрывая boosting или random trees в случае большого объема данных |

### Использование машинного обучения в компьютерном зрении

В общем все алгоритмы из таблицы 13-1 в качестве входного значения принимают вектор данных, состоящий из множества особенностей, где число особенностей может исчисляться тысячами. Предположим, имееться задача распознать определенного типа объект, например, человека. Первая проблема, с которой придеться столкнуться заключается в том, чтобы собрать и обучить метки, которые соответствуют положительным (человек присутствует в сцене) и отрицательным (человек отсутствует в сцене) случаям. Вскоре будет показано, что представление людей может быть разных масштабов: в виде нескольких пикселей на изображении или какой-то части тела, например, ухо. И даже хуже, люди зачастую будут перекрыты: мужчина внутри автомобиля; одна нога, видимая из-за дерева; лицо женщины. К тому же необходимо определение того, что именно имеется ввиду, когда говорят о человеке в сцене.

Сбор данных является следующей проблемой. Возникают следующие вопросы: собирать ли информацию о движениях; собирать ли другую информацию (такую, как время, сезон, температура, открыты ли ворота в сцене). Алгоритм, который ищет людей на пляже, может работать неверно в случае поиска людей на горнолыжном склоне. Необходимо фиксировать изменчивые данные: различные взгляды людей, различные источники света, погодные условия, тени и т.д.

После выполнения сбора большого объема данных, возникает вопрос как выделить метки? В начале необходимо определить, что такое "метка". При этом необходимо ли знать, где находится человек в сцене? Какие действия (бег, ходьба, ползанье, порядок следования) важны? В конечном счёте может потребоваться обработать миллион или более изображений. И как собственно маркировать всё это? Есть множество способов для выполнения исключения фона в контролируемых условиях и сбора сегментированных передних планов людей в сцене. Для выполнения классификации можно использовать платные или бесплатные сервисы.

После выполнения маркировки данных, необходимо решить, какие особенности необходимо выделить на объектах. Опять же необходимо знать, что делать после этого. Если люди всегда располагаются с правой стороны, то нет причин для использования инвариантно-вращающихся особенностей и выполнения вращения объектов заранее. В общем, необходимо искать особенности, которые выражают некоторую инвариантность объектов, такие как масштабно-независимые гистограммы градиентов или цветов или популярные SIFT особенности (Lowe’s SIFT feature demo (http://www.cs.ubc.ca/~lowe/keypoints/)). Если в сцене присутствует информация о фоне, то в начале может потребоваться удалить его, чтобы потом можно было выделить другие объекты. Затем может потребоватся выполнение обработки изображения, которая в свою очередь может состоять из нормализации изображения (масштабирование, вращение, гистограммы выравнивания и т.д.) и вычислении множества различных типов особенностей. Каждый из полученных векторов данных имеет метку, связанную с объектом, действием или сценой.

Зачастую, после того, как данные собраны и размещены в векторах особенностей, возникает необходимость в разбиении полученных данных во время обучения, проверки и тестирования. Это "лучший способ" выполнить обучение, проверку и тестирование в рамках перекрестной проверки. Т.е. данные разбиваются на K подмножеств и выполняется множество итераций обучения (возможно проверки) и тестирования, где каждая итерация состоит из различного набора данных, принимающие на себя роль обучения (проверки) и тестирования (как правило, одно обучение (возможно проверка) и цикл тестирования от 5 до 10 раз). Затем результаты тестирования отдельных итераций усредняются для получения окончательного результата. Перекрёстная проверка даёт более точную картину того, как будет работать классификатор на новом наборе данных. (В дальнейшем об этом будет рассказано более подробно.)

Теперь, когда данные сформированы, необходимо выбрать классификатор. Зачастую выбор классификатора продиктован соображениями в пользу вычислительности, данных или памяти. Для некоторых приложений, таких как онлайн строитель модели предпочтений пользователя, необходимо, чтобы обучение классификатора происходило быстро. В таком случае, такие алгоритмы, как nearest neighbors, normal Bayes или decision trees будут хорошим выбором. Если делается упор на память, то decision trees или neural networks наиболее эффективны. Если компонент времени обучения классификатора не критичен, но при этом важна скорость его работы, то neural networks хороший выбор, так же как и normal Bayes classifiers и support vector machines. Если компонент времени обучения классификатора не критичен, но при этом важна точность, то  boosting и random trees то что нужно. Если же необходим простой и понятный способ проверки выбранных особенностей, то decision trees или nearest neighbors хороший выбор. В первую очередь "из коробки" стоит попробовать boosting или random trees. 

	Усреднив все возможные типы распределения данных, все классификаторы выполняют одно и тоже. Таким образом, нельзя сказать, какой алгоритм из таблицы 13-1 является "лучшим". Для любого заданного распределения данных имеется наилучший классификатор. Поэтому на реальном наборе данных лучше всего испробовать максимально возможное количество классификаторов. В зависимости от преследуемых целей - произвести верный или быстрый рассчет; интерпретировать данные - различные классификаторы ведут себя по разному. 

### Важная переменная

Два алгоритма из таблицы 13-1 позволяют оценить эту переменную (более известную как "важная переменная"). Возникает вопрос: как, учитывая вектор особенностей, определить важность этих особенностей для точности классификатора? Binary decision trees делают это напрямую: они обучаются за счет выбора переменной, которая наилучшим образом разделяет данные каждого узла. Переменная верхнего узла является наиболее важной переменной; переменные следующего уровня являются следующими важными переменными и так далее. Random trees могут вычислить важную переменную, используя технику Leo Breiman (данная техника описана в работе "Looking Inside the Black Box" (www.stat.berkeley.edu/~breiman/wald2002-2.pdf)); эта техника может быть применима к любому классификатору, но на данный момент в OpenCV реализована только для decision и random trees.

Один из возможных вариантов использования важной переменнной сводиться к уменьшению числа особенностей, которые классификатор должен учитывать. Начиная с большого количества особенностей, классификатор обучается и впоследствии ищется важная переменная для каждой особенности относительно других особенностей.Впоследствии можно отбросить неважные особенности. Исключение незначительных особенностей увеличит скоростные характеристики (т.к. будет исключена обработка для вычисления этих особенностей), тем самым обучение и тестирование становиться быстрее. Кроме того, в случае недостаточного объёма данных, что зачастую и бывает, за счет исключения незначительных переменных можно повысить точность классификации; это ускоряет обработку с последующим получением лучшего результата.

Алгоритм получения важной переменной способом Breiman состоит из следующих шагов:

1. Обучение классификатора на множестве для обучения.

2. Использование множеств для проверки или тестирования для повышения точности классификатора.

3. Для каждой точки данных и выбранной особенности случайным образом выбирается новое значение для этой особенности среди значений особенностей из оставшегося набора данных (так называемая "выборка с заменой"). Это гарантирует, что распределение для этого признака будет оставаться тем же, как и в оригинальном наборе данных, только теперь актуальная структура или значение этой особенности стирается (потому что значение выбирается случайным образом из оставшегося набора данных).

4. Обучение классификатора на измененном множестве для обучения и последующего изменения точности классификатора на измененном множестве для тестирования или проверки. Если случайная особенность оказывает сильное влияние на точность, то эта особенность очень важна. В ином случае случайная особенность не так важна и является кандидатом для удаления.

5. Восстановление исходного набора для тестов или проверки и переход к следующей особенности, пока они не закончились. Результом является сортировка особенностей в порядке их важности.

Описанный алгоритм базируется на random trees и decision trees. Таким образом, random trees и decision trees можно использовать для определения переменных, которые действительно необходимо использовать в качестве особенностей; в последующем можно использовать облегченный вектор особенностей для обучения того же (или другого) классификатора.

### Диагностика проблем машинного обучения

Хорошая работа машинного обучения это скорее исскуство, чем наука. Алгоритмы зачастую "вроде" работают, но не так хорошо, как требуется. Именно в этот момент и проявляется исскуство - происходит выяснение и исправление того, что происходит не так. Данного раздела не хватит для разъяснения всех подробностей, однако, далее будет дан краткий обзор некоторых из наиболее распространенных проблем (профессор Andrew Ng из Stanford University предоставляет более подробную информацию в веб-лекциях, озаглавленные как "Советы по применению машинного обучения" (http://www.stanford.edu/class/cs229/materials/ML-advice.pdf)). Для начала некоторые эмпирические правила: большой объем данных разбивается на малые объемы данных, а лучшие особенности рапределяются по лучшим алгоритмам. В случае введения собственных особенностей - при их максимальной независимости друг от друга и минимальном изменении в различных условиях - то почти любой алгоритм будет работать хорошо. Помимо этого существуют две наиболее распростаненные проблемы:

*Необъективность*

	Предполагаемая модель слишком устойчивая, поэтому соответствующая модель не очень хорошая.

*Изменчивость*

	Алгоритм запоминает данные, *включающие* шум, поэтому он не может быть обобщен

На рисунке 13-1 показана базовая настройка для статистического машинного обучения. Работа сводиться к моделированию истинной функции *f*, которая преобразует основные входы в некий выход. Эта функция может иметь проблемы с регрессией (например, предсказание возраста человека по лицу) или проблему прогнозирования категории (например, идентификация личности по чертам лица). Проблемы, связанные с реальным миром, шум и непродуманные эффекты могут привести к тому, что получаемый выход может не соответствовать теоретическому. Например, при распознавании лица можно изучить модель за счет расстояния между глазами, рта и носа, идентифицирующие лицо. При этом изменения освещения, поступающие от соседней мерцающей лампы, приводят к шуму в измерениях, или плохо изготовленный объектив камеры приводит к систематическому искажению в измерениях, которые не будут рассмотрены как часть модели. Все это так же влияет и на точность.

![Рисунок 13-1 не найден](Images/Pic_13_1.jpg)

Рисунок 13-1. Настройки для статистического машинного обучения: классификатор обучается, чтобы соответствовать набору данных; истинная модель *f* почти всегда повреждена шумом или неизвестным воздействием

В двух верних областях рисунка 13-2 показано недостаточное и чрезмерное обучение, а в двух нижних областях этого же рисунка показаны последствия с точки зрения ошибки в процессе подготовки заданного размера. В левой части рисунка 13-2 показана попытка обучения классификатора для прогнозирования данных из нижней области рисунка 13-1. Если использовать слишком ограниченную модель - показанная четко видимой прямой пунктирной линией - то будет невозможно соответствовать базовой истинной параболе *f*, которая показана неясно видимой пунктирной линией. таким образом, данные предназначенные для обучения и тестирования будут плохими, даже при наличии большого объема данных. В этом случае возникает *необъективносить*, т.к. оба набора данных (для обучения и для тестирования) прогнозируются плохо. Правая часть рисунка 13-2 соответствует точному набору для обучения, но это приводит к бессмысленной функции, которой соответствует немного шума. Таким образом, запоминание набора для для обучения приводит и к запоминанию данных, содержащих шум. Как результат, набор данных для тестирования оставляет желать лучшего. Низкая погрешность при обучении в сочетании с большой погрешностью при тестировании указывает на проблему *изменчивости*.

![Рисунок 13-2 не найден](Images/Pic_13_2.jpg)

Рисунок 13-2. Плохая модель машинного обучения и её влияние на производительность процессов обучения и тестирования, где истинная функция графически показана неясно видимой пунктирной линией в верхней части рисунка: underfit модель (сверху слева) приводит к большой ошибке прогнозирования наборов данных для обучения и тестирования (снизу слева), в то время как overfit модель (сверху справа) приводит к малой ошибке набора для обучения и большой ошибке набора для тестирования (снизу справа)

Иногда необходимо соблюдать осторожность для нахождения верного решения проблемы. Если наборы данных для обучения и тестирования имеют малую ошибку, а алгоритм работает плохо в реальных условиях, то соответствующие наборы данных выбрано согласно нереальным условиям - возможно из-за того, что согласно этим условиям процессы сбора или моделирования осуществить проще. Если же алгоритм просто не может воспроизвести наборы для обучения или тестирования, то, возможно, используются не тот алгоритм, или не те особенности, которые после извлечения являются неэффективными, или просто нет "связей" в собранных данных. В таблице 13-2 приведены возможные варианты решения описанных проблем. Разумеется это не полный список возможных проблем и их решений. Для того, чтобы машинное обучение давало хорошие результаты, необходимо более тщательное проектирование и осмысление процесса сбора данных, а также более тщательный подбор функций для выполнения вычислений. Также неоходимо систематическое мышление для диагностики проблем машинного обучения.

Таблица 13-2. Проблемы машинного обучения и возможный вариант их решения; достижение наилучших особенностей поможет решить любую проблему

| Проблема | Возможное решение |
| -- | -- |
| Необъективность | * Добавление особенностей для достижения лучшего соответствия 
* Использование более мощного алгоритма |
| Изменчивость | * Использование большего объема данных для обучения поможет сгладить модель
* Использование меньшего количества особенностей поможет уменьшить переобучение
* использование менее мощного алгоритма |
| Хорошие результаты при тестировании/обучении, плохие в реальных условиях | * Сбор более реальных данных |
| Модель не распознает наборы для тестов или обучения | * Перепроектирование особенностей для лучшего отслеживания изменчивости данных
* Сбор новых, более реальных данных
* Использование более мощного алгоритма |

**Перекрестная проверка, самонастройка, кривые ROC и таблицы сопряженности**

